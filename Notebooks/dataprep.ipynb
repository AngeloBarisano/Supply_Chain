{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/angelo/Documents/Uni/Courses/Digital Transformation & Supply Chain/supply_chain_assignment\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_Churn = pd.read_csv(\"Data/Daily_Churned_customers_JET.csv\")\n",
    "\n",
    "df_input_accounts = pd.read_csv(\"Data/input_accounts_21_10_2022.csv\")\n",
    "\n",
    "df_tweets = pd.read_csv(\"Data/tweets-2022-10-21_justeattakeaway.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Churn Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_Churn[\"d_churn\"] = df_customer_Churn[\"Churned customers\"].shift(1) - df_customer_Churn[\"Churned customers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Churned customers</th>\n",
       "      <th>d_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2021</td>\n",
       "      <td>5757881</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/1/2021</td>\n",
       "      <td>5760714</td>\n",
       "      <td>-2833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/1/2021</td>\n",
       "      <td>5765953</td>\n",
       "      <td>-5239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/1/2021</td>\n",
       "      <td>5761176</td>\n",
       "      <td>4777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/1/2021</td>\n",
       "      <td>5755861</td>\n",
       "      <td>5315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>27/10/2022</td>\n",
       "      <td>8831343</td>\n",
       "      <td>-7003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>28/10/2022</td>\n",
       "      <td>8828483</td>\n",
       "      <td>2860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>29/10/2022</td>\n",
       "      <td>8850094</td>\n",
       "      <td>-21611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>30/10/2022</td>\n",
       "      <td>8853747</td>\n",
       "      <td>-3653.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>31/10/2022</td>\n",
       "      <td>8854181</td>\n",
       "      <td>-434.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>669 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Day  Churned customers  d_churn\n",
       "0      1/1/2021            5757881      NaN\n",
       "1      2/1/2021            5760714  -2833.0\n",
       "2      3/1/2021            5765953  -5239.0\n",
       "3      4/1/2021            5761176   4777.0\n",
       "4      5/1/2021            5755861   5315.0\n",
       "..          ...                ...      ...\n",
       "664  27/10/2022            8831343  -7003.0\n",
       "665  28/10/2022            8828483   2860.0\n",
       "666  29/10/2022            8850094 -21611.0\n",
       "667  30/10/2022            8853747  -3653.0\n",
       "668  31/10/2022            8854181   -434.0\n",
       "\n",
       "[669 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customer_Churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Data analysis of the platform’s Twitter data\n",
    "\n",
    "For the next part of the assignment you would be asked to put yourself in the shoes of the data analyst working at the platform JustEatTakeaway.com. You are asked by the platform management to explore whether the social media data could be useful for the platform to learn how the social media users (and potential customers) perceive the announcements about different innovations. Specifically, the platform is active in several accounts on Twitter regularly posting news and messages and replying to customers. You are asked to find out what could the platform management learn about users’ perception of its innovations from the user engagement with the platform’s tweets.\n",
    "\n",
    "For that, you are provided with the data on daily customer churn from JustEatTakeaway.com and tweets from the Twitter accounts of JustEatTakeaway and their competitors, Deliveroo and UberEats. The customer churn data covers the period of 01.2021 - 10.2022 and tweets cover the period of 11.2010-10.2022.\n",
    "\n",
    "The data analysis should be performed using python, for example, the libraries for data manipulation (pandas), descriptive analysis (pandas), graphical analysis (seaborn), regressions (statsmodels) and sentiment analysis (nltk/vader). However, you may choose any other suitable libraries.\n",
    "\n",
    "You may choose any relevant methods for your descriptive analysis and / or regression analysis.\n",
    "\n",
    "You are welcome to do feature engineering and if you create more than 5 additional features (independent variables) you may get a bonus of 0.5 points.*Creating a set of dummies for one variable counts as one feature, for example, the set of year dummies counts as one feature engineered.\n",
    "\n",
    "\n",
    "\n",
    "### Please, address the following questions:\n",
    "\n",
    " \n",
    "\n",
    "Describe the platform’s strategy on Twitter:\n",
    "2.1 What are the main topics the company tweets about? What are the most used words / hashtags / bigrams (trigrams)? How often and in which moments of time does the platform post tweets most often?* (1 slide)\n",
    "\n",
    "*Before you analyze the texts of tweets, please, preprocess the texts of tweets. You can find the list of simple preprocessing steps below, but you may also do any more sophisticated preprocessing (upon your choice).\n",
    "\n",
    "2.2 Please, compute the sentiment scores for each tweet using nltk (vader) library or any other library of your choice. You may also engineer any additional variables based on computed sentiment scores. How could you describe the platform’s tweets based on their sentiment scores? (1 slide)\n",
    "\n",
    " \n",
    "\n",
    "What features of the platform’s tweets are related to higher / lower user engagement with the tweets as measured by the number of  likes, retweets, or replies per tweet? To answer this question, please, run the regression analysis. As dependent variables, you may use the number of likes, retweets and / or replies to each tweet of the platform. As independent variables, you may use any relevant features from the Twitter data set, any additional features you created, and the sentiment scores from point 2.2 (or any other features you engineered based on sentiment scores).\n",
    "\n",
    "\n",
    "3.1 Is the use of positive / negative emotional words in the company’s tweets (original posts or replies) related to higher / lower user engagement as measured by the number of  likes, retweets? (1 slide)\n",
    "\n",
    "3.2 Do your findings hold for any time period or can you observe any outstanding time or seasonal patterns? For your analysis you may check any periods of interest, for example, covid-19 lockdowns, summer months, holidays, weekly patterns, time of the day patterns. (1 slide)\n",
    "\n",
    "3.3 Please, check whether user engagement with tweets of JustEatTakeaway.com is associated (or correlated) with customer churn? Do you observe any temporal patterns in this association, i.e. does this association differ depending what period you consider? How can you interpret the observed associations? (1 slide)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Data analysis of the platform’s Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data Preprocessing\n",
    "\n",
    "##### 1. Remove all non-character signs and stop words (Stop words are a set of commonly used words in a language that do not have any meaning. Examples of stop words in English are “a”, “the”, “is”, “are” and etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from termcolor import colored\n",
    "import math\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_vocabulary(vectorizer, word_size=15, words_per_line=10):\n",
    "    words = vectorizer.get_feature_names()\n",
    "\n",
    "    print(f'Vocabulary size: {len(words)} words')\n",
    "\n",
    "    word_format = f'<{word_size}'\n",
    "    for l in np.array_split(words, math.ceil(len(words) / words_per_line)):\n",
    "        print(''.join([f'{x:{word_format}}' for x in l]))\n",
    "\n",
    "\n",
    "def show_bow(vectorizer, bow, word_size=15, words_per_line=8):\n",
    "    words = vectorizer.get_feature_names()\n",
    "\n",
    "    word_format = f'<{word_size}'\n",
    "    for l in np.array_split(list(zip(words, bow)), math.ceil(len(words) / words_per_line)):\n",
    "        print(' | '.join([colored(f'{w:{word_format}}:{n:>2}', 'grey') if int(n) == 0 else colored(f'{w:{word_format}}:{n:>2}', on_color='on_yellow', attrs=['bold']) for w, n in l ]))\n",
    "\n",
    "def show_bow_float(vectorizer, bow, word_size=15, words_per_line=6):\n",
    "    words = vectorizer.get_feature_names()\n",
    "\n",
    "    word_format = f'<{word_size}'\n",
    "    for l in np.array_split(list(zip(words, bow)), math.ceil(len(words) / words_per_line)):\n",
    "        print(' | '.join([colored(f'{w:word_format}:{float(n):>0.2f}', 'grey') if float(n) == 0 else colored(f'{w:word_format}:{float(n):>0.2f}', on_color='on_yellow', attrs=['bold']) for w, n in l ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           @FoodNetwork flats for the win\n",
       "1        @PopTartsUS that's too many flavors at once bro 🤔\n",
       "2                                    @AuntieAnnes retweet.\n",
       "3        @_MarieGrey iS uR rEfRiGeRaToR rUNniNg BeCAuSe...\n",
       "4        @Drizly extra points for putting more water in...\n",
       "                               ...                        \n",
       "18591    @panikosgeor @Deliveroo @UberEats Hi Panikos, ...\n",
       "18592            @Gerdav74 Eet smakelijk alvast! 🍣 ^Isabel\n",
       "18593    @JanKarens @tonnyw @Kwalitaria Toch wil ik je ...\n",
       "18594    @MartinMunSigra Hee tas! Waar ga je met die be...\n",
       "18595    @bezemsteeI Hmmm, okay.. Ik kan helaas hier ni...\n",
       "Name: text, Length: 18567, dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional  = ['rt','rts','retweet'] #we'll store additional stopwords here\n",
    "\n",
    "swords = set().union(stopwords.words(['dutch', \"english\"]),additional)\n",
    "\n",
    "#replace all signs and stopwords in tweets and tokenize tweets (tokenization means splitting up a larger body of text into pieces such as words, keywords, phrases, symbols and other elements called tokens; in our case we can split the tweets into words)\n",
    "df_tweets.drop_duplicates(subset='text',inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m w_tokenizer \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mtokenize\u001b[39m.\u001b[39mWhitespaceTokenizer()\n\u001b[1;32m      2\u001b[0m lemmatizer \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mstem\u001b[39m.\u001b[39mWordNetLemmatizer()\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmatize_text\u001b[39m(text):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "df_tweets['text_lemmatized']\n",
    "df_tweets['text_lemmatized'] = df_tweets.text.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23819/390628904.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  .str.replace('(@[a-z0-9]+)\\w+',' ')\\\n",
      "/tmp/ipykernel_23819/390628904.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  .str.replace('(http\\S+)', ' ')\\\n",
      "/tmp/ipykernel_23819/390628904.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  .str.replace('([^0-9a-z \\t])',' ')\\\n",
      "/tmp/ipykernel_23819/390628904.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  .str.replace(' +',' ')\\\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "df_tweets['processed_text'] = df_tweets['text'].str.lower()\\\n",
    "            .str.replace('(@[a-z0-9]+)\\w+',' ')\\\n",
    "            .str.replace('(http\\S+)', ' ')\\\n",
    "            .str.replace('([^0-9a-z \\t])',' ')\\\n",
    "            .str.replace(' +',' ')\\\n",
    "            .apply(lambda x: [i for i in x.split() if not i in swords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             [flats, win]\n",
       "1                                     [many, flavors, bro]\n",
       "2                                                       []\n",
       "3        [mariegrey, ur, refrigerator, running, lol, jk...\n",
       "4            [extra, points, putting, water, bowl, cheers]\n",
       "                               ...                        \n",
       "18591    [hi, panikos, restaurants, indicate, use, deli...\n",
       "18592                     [eet, smakelijk, alvast, isabel]\n",
       "18593    [vragen, even, dm, sturen, hiervoor, open, sta...\n",
       "18594            [hee, tas, waar, ga, bezorger, toe, iris]\n",
       "18595    [hmmm, okay, helaas, terugvinden, voucher, zom...\n",
       "Name: processed_text, Length: 18567, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_tweets['processed_text'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Propper preprocessing using a count vectorizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtering by Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary: 3513\n"
     ]
    }
   ],
   "source": [
    "count = CountVectorizer(\n",
    "    stop_words=swords,\n",
    "    token_pattern=r'[a-z]+\\w*',\n",
    "    max_features=50000,\n",
    "    min_df=5,\n",
    "    max_df=0.8\n",
    ")\n",
    "tf = count.fit_transform(df_tweets.text)\n",
    "count.vocabulary_\n",
    "vocab_df = count.get_feature_names()\n",
    "print(f'Size of vocabulary: {len(vocab_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()\n",
    "# count.fit(df_tweets.text)\n",
    "# show_vocabulary(count)\n",
    "tf = count.fit_transform(df_tweets['text'])\n",
    "count.vocabulary_\n",
    "count.get_feature_names()\n",
    "tf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming/Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wn = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(max_df=0.8, max_features=1500, min_df=2, ngram_range=(1, 3),\n",
       "                stop_words=&#x27;english&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_df=0.8, max_features=1500, min_df=2, ngram_range=(1, 3),\n",
       "                stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(max_df=0.8, max_features=1500, min_df=2, ngram_range=(1, 3),\n",
       "                stop_words='english')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "count = CountVectorizer(\n",
    "    stop_words='english',\n",
    "    ngram_range=(1,3),    # will create a vocabulary with 1-gram and 2-grams\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    max_features=1500\n",
    ")\n",
    "\n",
    "count.fit(df_tweets.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1500 words\n",
      "000                      10                       100                      19uzbmarzd               20                       9hqhr1pvi1               \n",
      "aan                      aan het                  aan het wachten          able                     able drop                able drop dm             \n",
      "able follow              able follow request      able resolve             able resolve effectively account                  account additional       \n",
      "account additional detailsaccount alternatively    account alternatively contactaccount assist           account assist better    account details          \n",
      "account details email    account dm               account email            account email address    account look             account order            \n",
      "account order id         account screenshot       account screenshot showingaccount trip             account trip details     act                      \n",
      "act responsibly          act responsibly respectfullyadditional               additional details       additional details issue address                  \n",
      "address details          address let              address let know         address linked           address linked account   address linked uber      \n",
      "address mobile           address mobile number    address order            address order number     address phone            address phone number     \n",
      "afdeling                 agency                   agency couriers          agency couriers self     agents                   ah                       \n",
      "aimée                    aimée https              aimée https rezkjo2sd1   al                       als                      als je                   \n",
      "alternatively            alternatively contact    alternatively contact linkaltijd                   altijd een               altijd een dm            \n",
      "alvast                   amazing                  amp                      apologies                apologies hasn           apologies hasn fixed     \n",
      "app                      app dm                   app dm account           app help                 app help section         app website              \n",
      "appreciate               asap                     asap choose              asap choose rider        assist                   assist asap              \n",
      "assist asap choose       assist better            assist better way        assistance               assistance kindly        assistance kindly follow \n",
      "associated               attention                attention like           attention like deeper    available                avond                    \n",
      "award                    awards                   aware                    away                     bearing                  bedankt                  \n",
      "bedoeling                begrijp                  begrijp dat              ben                      bent                     best                     \n",
      "best thing               best thing report        best wishes              bestelling               bestelnummer             bestelnummer dan         \n",
      "bestelnummer dan ga      bestelnummer dan kijk    bestelnummer een         bestelnummer een dm      bestelnummer en          better                   \n",
      "better way               better way kindly        bezorger                 bezorgers                bezorgers dienst         big                      \n",
      "bij                      bit                      boxes                    boxes page               boxes page https         bp                       \n",
      "bp https                 brand                    brief                    brief manner             brief manner dm          bringing                 \n",
      "bringing attention       bringing attention like  business                 busy                     ca                       campaign                 \n",
      "card                     care                     case                     caused                   celebrate                celebrating              \n",
      "chance                   characters               characters sd            charity                  charity partner          charity partner foodcycle\n",
      "chase                    chat                     check                    check pc                 check pc https           checked                  \n",
      "choose                   choose rider             choose rider user        chris                    close                    close eye                \n",
      "closer                   closer look              closer look drop         closer look email        closer look share        code                     \n",
      "code received            code received assist     com                      com limited              com limited characters   com ll                   \n",
      "com relevant             com relevant details     com soons                com soons om             companies                companies agency         \n",
      "companies agency couriersconcern                  concern assist           concerned                confirm                  congratulations          \n",
      "contact                  contact app              contact app help         contact link             contact link https       contractors              \n",
      "correct                  correct support          correct support team     couldn                   courier                  courier companies        \n",
      "courier companies agency couriers                 couriers self            couriers self employed   currently                customer                 \n",
      "customer information     customer security        customer security extremelycustomers                customers doors          customers doors employed \n",
      "daar                     dan                      dan ga                   dan ga ik                dan graag                dan help                 \n",
      "dan help ik              dan kan                  dan kijk                 dan kijk ik              dan mag                  dan mag je               \n",
      "dat                      dat dit                  dat het                  dat je                   dat jij                  dat jouw                 \n",
      "dat jouw bestelling      dat vervelend            dat vervelend kun        date                     date partner             date partner driver      \n",
      "davey                    davey https              davey https rezkjo2sd1   david                    day                      db                       \n",
      "db https                 db https it5usdsrlk      dc                       dc https                 deeper                   deeper look              \n",
      "deeper look definitely   definitely               definitely like          definitely like hear     delay                    delicious                \n",
      "delighted                deliver                  delivered                delivering               delivering food          deliveroo                \n",
      "deliveroohelp            delivery                 delivery drivers         details                  details date             details date partner     \n",
      "details dm               details dms              details dms soon         details email            details email address    details issue            \n",
      "details issue assist     details issue enquiry    details ll               details member           details member team      details social           \n",
      "details social uk        details twitter          details twitter justeattakeawaydeze                     dg                       did                      \n",
      "didn                     didn receive             didn receive order       die                      dienst                   direct                   \n",
      "direct message           direct message assist    directed                 directed correct         directed correct support directly                 \n",
      "directly independent     directly independent restaurantsdisappointed             disappointed hear        disappointing            disappointing hear       \n",
      "discuss                  dit                      dit graag                dit graag voor           dm                       dm able                  \n",
      "dm able resolve          dm account               dm account details       dm account email         dm check                 dm details               \n",
      "dm email                 dm email address         dm email twitter         dm information           dm kunnen                dm kunnen sturen         \n",
      "dm ll                    dm ll sm                 dm look                  dm met                   dm order                 dm order id              \n",
      "dm order number          dm sturen                dm sturen met            dm te                    dm te sturen             dm update                \n",
      "dm willen                dm willen sturen         dms                      dms look                 dms look moment          dms provide              \n",
      "dms provide assistance   dms soon                 dms soon om              doen                     doesn                    doing                    \n",
      "don                      door                     doors                    doors employed           driver                   drivers                  \n",
      "drivers delivering       drop                     drop dm                  drop dm order            drop email               drop order               \n",
      "dropped                  dropping                 dropping dm              dropping dm order        dus                      eat                      \n",
      "eat https                eat uk                   eats                     eats app                 eats support             eats support team        \n",
      "echter                   een                      een dm                   een dm kunnen            een dm met               een dm sturen            \n",
      "een dm te                een dm willen            eet                      eet smakelijk            effectively              effectively keeping      \n",
      "effectively keeping eye  eigen                    eigen bezorgers          elaborate                elaborate concern        elaborate query          \n",
      "elaborate query brief    em                       email                    email address            email address details    email address let        \n",
      "email address linked     email address mobile     email address order      email address phone      email details            email details social     \n",
      "email relevant           email relevant details   email twitter            email twitter justeattakeawayemma                     employed                 \n",
      "employed directly        employed directly independentemployed independent     employed independent contractorsen                       en mailadres             \n",
      "end                      enjoy                    enquiry                  enquiry elaborate        enquiry elaborate concerner                       \n",
      "erg                      et                       euroovision              eva                      eva https                eva https rezkjo2sd1     \n",
      "event                    exact                    excited                  excuses                  excuses voor             excuses voor het         \n",
      "expect                   expect drivers           expected                 experience               experienced              experiencing             \n",
      "extremely                extremely important      extremely important multipleeye                      eye response             faced                    \n",
      "fantastic                favour                   favourite                feedback                 feel                     feel free                \n",
      "femke                    femke https              femke https rezkjo2sd1   fijn                     fijn om                  fijn om te               \n",
      "fijne                    fix                      fixed                    fixed dm                 fixed dm account         follow                   \n",
      "follow request           follow request dms       follow support           follow support page      follow twitter           follow twitter account   \n",
      "food                     food customers           food customers doors     food delivery            foodcycle                fooi                     \n",
      "forward                  free                     future                   ga                       ga ik                    ga ik het                \n",
      "gaat                     gabriela                 gabriela https           geen                     geleverd                 getting                  \n",
      "getting touch            geval                    glad                     goed                     going                    good                     \n",
      "got                      graag                    graag een                graag met                graag met je             graag verder             \n",
      "graag voor               graag voor je            great                    guidance                 guidance support         ha                       \n",
      "hand                     hand drop                hand ha                  hand send                hand send email          happened                 \n",
      "happily                  happily look             happy                    happy help               happy help dm            happy help follow        \n",
      "happy help send          happy look               hard                     hasn                     hasn fixed               hasn fixed dm            \n",
      "hasn resolved            hasn resolved dm         head                     hear                     hear dm                  hear dm account          \n",
      "hear like                hear mind                hear mind dropping       hear order               hear pop                 hear pop order           \n",
      "hear send                hear send dm             hear send email          hear ve                  heb                      heb je                   \n",
      "hebben                   hebt                     hebt ontvangen           heeft                    helaas                   helemaal                 \n",
      "help                     help dm                  help dm email            help follow              help follow support      help ik                  \n",
      "help ik je               help ik jou              help je                  help section             help section app         help section ll          \n",
      "help send                help send email          help support             helpen                   helps                    het                      \n",
      "het ongemak              het ongemak zou          het restaurant           het voor                 het voor je              het wachten              \n",
      "het wachten bent         hey                      hey like                 hey sorry                hey sorry hear           hey thanks               \n",
      "hey thanks getting       hey thanks reaching      hi                       hi dm                    hi dm email              hi happy                 \n",
      "hi happy help            hi send                  hi sorry                 hi sorry hear            hi thank                 hi thank reaching        \n",
      "hi thanks                hi thanks getting        hi thanks letting        hi thanks reaching       hi ve                    hi wat                   \n",
      "hi wat vervelend         hier                     hierin                   high                     high standards           high standards line      \n",
      "hoi                      hoi hoi                  hoi wat                  hoi wat vervelend        hold                     hold high                \n",
      "hold high standards      hoop                     hoop dat                 hoor                     hope                     horen                    \n",
      "horen dat                horen dat je             horen dat jij            horen dat jouw           horen zeg                horen zou                \n",
      "hot                      http                     https                    https 19uzbmarzd         https 9hqhr1pvi1         https it5usdsrlk         \n",
      "https it5usdszas         https it5usea2cs         https qrarb3a7vt         https rezkjo2sd1         https tqzmrofyma         https tqzmrofyma uber    \n",
      "huge                     hun                      hungry                   id                       id additional            id additional details    \n",
      "id assist                id assist asap           id assist better         id direct                id direct message        ideal                    \n",
      "iets                     ik                       ik begrijp               ik begrijp dat           ik dit                   ik dit graag             \n",
      "ik graag                 ik graag met             ik heb                   ik help                  ik help je               ik het                   \n",
      "ik het voor              ik hoop                  ik hoop dat              ik je                    ik je graag              ik jou                   \n",
      "ik jou graag             ik kan                   ik kijk                  ik kijk graag            ik met                   ik snap                  \n",
      "ik snap dat              ik wil                   important                important multiple       important multiple securityincluding                \n",
      "inconvenience            inconvenience caused     independent              independent contractors  independent restaurants  independent restaurants work\n",
      "inderdaad                industry                 info                     info issue               informatie               information              \n",
      "insight                  investigate              iris                     iris https               iris https rezkjo2sd1    isabel                   \n",
      "isn                      isn like                 isn like hear            issue                    issue assist             issue assist better      \n",
      "issue enquiry            issue enquiry elaborate  issues                   it5usdsrlk               it5usdszas               it5usea2cs               \n",
      "items                    jade                     james                    jammer                   jammer om                jammer om te             \n",
      "je                       je bestelling            je een                   je graag                 je graag verder          je kan                   \n",
      "je mag                   je mee                   je mee femke             je mee iris              je mij                   je mij een               \n",
      "je mij jouw              je na                    je na romy               je nakijken              je nakijken davey        je ons                   \n",
      "je ordernummer           jij                      jij jouw                 jij mij                  jij mij een              john                     \n",
      "jou                      jou graag                jou graag verder         jouw                     jouw bestelling          jouw bestelnummer        \n",
      "jouw bestelnummer dan    jouw bestelnummer en     jouw dm                  jouw mailadres           jouw ordernummer         jouw ordernummer dan     \n",
      "jouw vouchercode         just                     just eat                 just eat https           just eat uk              just responded           \n",
      "just responded dm        justeat                  justeat_it               justeat_uk               justeatie                justeattakeaway          \n",
      "justeattakeaway com      justeattakeaway com limitedjusteattakeaway com ll   justeattakeaway com relevantjusteattakeaway com soonsjusteatuk                \n",
      "kan                      kan ik                   kan je                   kan jij                  kan jij mij              keen                     \n",
      "keen look                keeping                  keeping eye              keeping eye response     kijk                     kijk graag               \n",
      "kijk graag met           kijk ik                  kijk ik dit              kijk ik graag            kijken                   kindly                   \n",
      "kindly dm                kindly follow            kindly follow twitter    kindly send              know                     know details             \n",
      "know dm                  know dm order            know order               know order details       kun                      kun je                   \n",
      "kun je mij               kunnen                   kunnen sturen            kunnen sturen met        lang                     langer                   \n",
      "lend                     lend hand                lend hand ha             lend hand send           leon                     let                      \n",
      "let know                 let know details         let know order           letting                  letting know             letting know dm          \n",
      "like                     like closer              like closer look         like deeper              like deeper look         like hear                \n",
      "like hear mind           like hear pop            like help                like lend                like lend hand           like look                \n",
      "like look lend           limited                  limited characters       limited characters sd    line                     line expect              \n",
      "line expect drivers      link                     link https               linked                   linked account           linked account additional\n",
      "linked account assist    linked account look      linked account order     linked account screenshotlinked account trip      linked uber              \n",
      "little                   live                     lk                       ll                       ll check                 ll check pc              \n",
      "ll close                 ll close eye             ll closer                ll closer look           ll directed              ll directed correct      \n",
      "ll follow                ll happily               ll happily look          ll look                  ll look rb               ll sm                    \n",
      "ll sm https              ll sorted                ll sorted best           local                    london                   look                     \n",
      "look able                look able drop           look asap                look definitely          look definitely like     look dm                  \n",
      "look dm account          look drop                look drop dm             look email               look email details       look issue               \n",
      "look lend                look lend hand           look moment              look pop                 look rb                  look send                \n",
      "look send dm             look share               look share details       looked                   looking                  looks                    \n",
      "love                     love help                luck                     maar                     mag                      mag je                   \n",
      "mail                     mailadres                mailadres dan            make                     maken                    making                   \n",
      "making aware             manner                   manner dm                manner dm able           mark                     marketing                \n",
      "massive                  mcdonalds                meal                     meals                    measures                 measures place           \n",
      "measures place protect   mee                      mee aimée                mee femke                mee iris                 mee iris https           \n",
      "meer                     meer informatie          member                   member team              member team pick         menulog                  \n",
      "message                  message assist           message assist asap      message assist better    met                      met een                  \n",
      "met het                  met je                   met je mee               met je ordernummer       met jouw                 met jouw bestelnummer    \n",
      "met jouw mailadres       met jouw ordernummer     mij                      mij een                  mij een dm               mij jouw                 \n",
      "mijn                     mijn excuses             mijn excuses voor        mijn oprechte            mijn oprechte excuses    million                  \n",
      "mind                     mind dropping            mind dropping dm         misschien                mk                       mm                       \n",
      "mobile                   mobile number            mobile number email      mobile number linked     mocht                    mocht je                 \n",
      "moet                     mogelijk                 moment                   momenteel                month                    multiple                 \n",
      "multiple security        multiple security measuresmv                       na                       na romy                  naar                     \n",
      "nakijken                 nakijken davey           nakijken davey https     natuurlijk               need                     need hand                \n",
      "new                      news                     niet                     night                    nocontextbrits           nog                      \n",
      "nog niet                 note                     nous                     number                   number bp                number closer            \n",
      "number closer look       number details           number dm                number dm email          number dm ll             number dms               \n",
      "number email             number email address     number linked            number linked account    number ll                number ll check          \n",
      "number ll closer         number ll look           number look              number order             number order number      offer                    \n",
      "offer guidance           offer guidance support   oh                       om                       om dit                   om een                   \n",
      "om https                 om https it5usdsrlk      om te                    om te horen              ongemak                  ongemak zou              \n",
      "online                   ons                      ons altijd               ons altijd een           ons een                  ons een dm               \n",
      "ontvang                  ontvang ik               ontvangen                ontzettend               ontzettend vervelend     ontzettend vervelend om  \n",
      "onze                     ook                      op                       op jouw                  op jouw bestelling       open                     \n",
      "opportunity              oprechte                 oprechte excuses         order                    order assist             order assist better      \n",
      "order details            order help               order id                 order id additional      order id assist          order id direct          \n",
      "order number             order number bp          order number closer      order number details     order number dm          order number dms         \n",
      "order number email       order number ll          order resolved           order resolved dm        ordering                 ordernummer              \n",
      "ordernummer dan          ordernummer dan kijk     orders                   page                     page https               page https tqzmrofyma    \n",
      "partner                  partner driver           partner foodcycle        partners                 partnership              party                    \n",
      "party courier            party courier companies  patience                 paul                     pay                      pc                       \n",
      "pc https                 pc https it5usdsrlk      people                   people uk                phone                    phone number             \n",
      "phone number email       phone number look        phone number order       pick                     pick soon                pick soon possible       \n",
      "picked                   pizza                    place                    place protect            place protect customer   platform                 \n",
      "pleased                  pleased hear             pop                      pop dm                   pop dm order             pop order                \n",
      "pop order number         possible                 possible mk              problem                  promo                    promo code               \n",
      "promo code received      protect                  protect customer         protect customer informationprovide                  provide additional       \n",
      "provide additional detailsprovide assistance       provide assistance kindlyqrarb3a7vt               query                    query brief              \n",
      "query brief manner       questions                ra                       ra https                 ra https it5usdsrlk      rb                       \n",
      "reach                    reach help               reaching                 reaching bringing        reaching bringing attentionreaching customer        \n",
      "reaching customer securityreaching doesn           reaching like            reaching like closer     reaching like look       read                     \n",
      "read https               ready                    ready look               real                     really                   really like              \n",
      "really love              really sorry             receive                  receive order            receive order resolved   received                 \n",
      "received assist          received assist better   referring                regarding                registered               relevant                 \n",
      "relevant details         relevant details member  relevant details twitter replied                  replied dm               reply                    \n",
      "reply dms                report                   report help              report help section      request                  request dms              \n",
      "request dms provide      resolve                  resolve effectively      resolve effectively keepingresolved                 resolved dm              \n",
      "resolved dm account      respectfully             respectfully times       responded                responded dm             response                 \n",
      "responsibly              responsibly respectfully responsibly respectfully timesrestaurant               restaurant partners      restaurants              \n",
      "restaurants work         restaurants work party   review                   rezkjo2sd1               rider                    rider user               \n",
      "rider user sure          right                    right away               romy                     rt                       sam                      \n",
      "sander                   sarah                    say                      screenshot               screenshot promo         screenshot promo code    \n",
      "screenshot showing       screenshot showing promo sd                       section                  section app              section app dm           \n",
      "section ll               sector                   security                 security extremely       security extremely importantsecurity measures        \n",
      "security measures place  self                     self employed            self employed independentsend                     send details             \n",
      "send dm                  send dm details          send dm order            send email               send email address       send email relevant      \n",
      "send email twitter       send order               send order number        sending                  sent                     sent reply               \n",
      "service                  share                    share details            share details dms        share guidance           share order              \n",
      "share order number       sharing                  showing                  showing promo            showing promo code       situation                \n",
      "sm                       sm https                 sm https it5usdsrlk      smakelijk                snap                     snap dat                 \n",
      "snel                     snel mogelijk            social                   social team              social uk                social uk justeattakeaway\n",
      "soon                     soon om                  soon om https            soon possible            soon possible mk         soon ra                  \n",
      "soons                    soons om                 sorry                    sorry delay              sorry didn               sorry didn receive       \n",
      "sorry hasn               sorry hasn resolved      sorry hear               sorry hear dm            sorry hear like          sorry hear order         \n",
      "sorry hear send          sorry ll                 sorry ll sorted          sorted                   sorted best              sorted best thing        \n",
      "sorted dm                sound                    speak                    standards                standards line           standards line expect    \n",
      "stem                     stemambassadors          students                 sturen                   sturen dan               sturen dan kijk          \n",
      "sturen ik                sturen met               sturen met je            sturen met jouw          support                  support dc               \n",
      "support link             support link https       support page             support page https       support team             support team assist      \n",
      "sure                     sure ll                  sure ll directed         takeaway                 takeaways                taking                   \n",
      "tap                      te                       te horen                 te horen dat             te horen zeg             te horen zou             \n",
      "te sturen                team                     team assist              team assist asap         team pick                team pick soon           \n",
      "tech                     thank                    thank patience           thank reaching           thank reaching like      thanks                   \n",
      "thanks bringing          thanks bringing attentionthanks getting           thanks getting touch     thanks letting           thanks letting know      \n",
      "thanks making            thanks making aware      thanks reaching          thanks reaching bringing thanks reaching customer thanks reaching doesn    \n",
      "thanks reaching like     thing                    thing report             thing report help        things                   think                    \n",
      "time                     times                    toch                     today                    touch                    tqzmrofyma               \n",
      "tqzmrofyma uber          tqzmrofyma uber eats     trip                     trip details             trip details date        try                      \n",
      "trying                   tweet                    twitter                  twitter account          twitter account alternativelytwitter just             \n",
      "twitter just eat         twitter justeattakeaway  twitter justeattakeaway comuber                     uber account             uber eats                \n",
      "uber eats app            uber eats support        uberdonteats             ubereats                 uit                      uk                       \n",
      "uk justeattakeaway       uk justeattakeaway com   ukcelebrations           understand               update                   use                      \n",
      "user                     user sure                user sure ll             using                    van                      van je                   \n",
      "ve                       ve dm                    ve got                   ve just                  ve just responded        ve responded             \n",
      "ve responded dm          ve sent                  verder                   verder gabriela          verder met               verder met je            \n",
      "verder voor              verder voor je           vervelend                vervelend dat            vervelend kun            vervelend kun je         \n",
      "vervelend om             vervelend om te          volunteers               voor                     voor het                 voor het ongemak         \n",
      "voor je                  voor je kan              voor je na               voor je nakijken         votre                    voucher                  \n",
      "vouchercode              vous                     vragen                   waar                     wachten                  wachten bent             \n",
      "wait                     waiting                  wanneer                  want                     wat                      wat jammer               \n",
      "wat jammer om            wat ontzettend           wat ontzettend vervelend wat vervelend            wat vervelend dat        wat vervelend om         \n",
      "watch                    way                      way kindly               wearejusteat             website                  week                     \n",
      "weekend                  weer                     wel                      welcome                  welke                    wens                     \n",
      "wij                      wil                      wil je                   wil je mij               willen                   willen sturen            \n",
      "willen sturen dan        willen sturen met        wishes                   won                      worden                   wordt                    \n",
      "work                     work party               work party courier       working                  working hard             world                    \n",
      "wrong                    year                     yes                      yesterday                zal                      zeg                      \n",
      "zeg zou                  zeker                    zelf                     zie                      zij                      zijn                     \n",
      "zo                       zo lang                  zo snel                  zo snel mogelijk         zodat                    zodat ik                 \n",
      "zou                      zou je                   zou je mij               zou jij                  zou jij mij              zullen                   \n"
     ]
    }
   ],
   "source": [
    "show_vocabulary(count, word_size=25, words_per_line=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Stemming - an algorithm to categorize similar words (or words with the same roots) into one. We can use the porter stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          [flat, win]\n",
       "1                                  [mani, flavor, bro]\n",
       "2                                                   []\n",
       "3    [mariegrey, ur, refriger, run, lol, jk, happi,...\n",
       "4              [extra, point, put, water, bowl, cheer]\n",
       "5                                  [gonna, say, thing]\n",
       "6                       [ok, got, earnest, lol, outta]\n",
       "7                   [liter, morn, meet, w, boss, week]\n",
       "8                                   [watch, one, hand]\n",
       "9                                       [icon, around]\n",
       "Name: stemmed, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "df_tweets['stemmed'] = df_tweets['processed_text'].apply(lambda x: [ps.stem(i) for i in x if i != ''])\n",
    "\n",
    "df_tweets['stemmed'].head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sentiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/angelo/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.sentiment.vader as vd\n",
    "from nltk import download\n",
    "download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    9762\n",
       " 1    4657\n",
       " 2    3745\n",
       "-1     181\n",
       " 3     171\n",
       " 4      44\n",
       " 5       3\n",
       " 6       2\n",
       "-2       2\n",
       "Name: sentiment_score, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia = vd.SentimentIntensityAnalyzer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "df_tweets['sentiment_score'] = df_tweets['processed_text'].apply(lambda x: sum([ sia.polarity_scores(i)['compound'] for i in word_tokenize( ' '.join(x) )]) )\n",
    "df_tweets[['processed_text','sentiment_score']].head(n=10)\n",
    "df_tweets['sentiment_score'].apply(lambda x: round(x,)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 What are the main topics the company tweets about? What are the most used words / hashtags / bigrams (trigrams)? How often and in which moments of time does the platform post tweets most often?* (1 slide)\n",
    "\n",
    "wordcloud, n grams, LDA, SDA, show vocabulary and also show vocabulary ba document via LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Please, compute the sentiment scores for each tweet using nltk (vader) library or any other library of your choice. You may also engineer any additional variables based on computed sentiment scores. How could you describe the platform’s tweets based on their sentiment scores? (1 slide)\n",
    "\n",
    "here we should find the sentiment score of each document; classify it and then build a regression on this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('supply_chain_assignment': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "441823ab0e6902f799e47890707b23162276548d32ed8434c50c44bed75965d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
